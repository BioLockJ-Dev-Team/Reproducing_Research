
# This is how BioLockJ knows it is running on a cluster.
pipeline.env=cluster

# The number of scripts/nodes launched for each module
script.numWorkers=12
# The SraDownload module does not run more efficiently
# by having samples share a worker script. But spreading samples
# accross as many scripts as possible can reduce the number of restarts
# that are required to get all downloads to complete.
SraDownload.numWorkers=1000

# If worker nodes on this system do not allow internet access,
# You can use this line to force the SRA module to run on the head node.
# SraDownload.batchCommand=/bin/bash

# resources that we expect to need for most modules
cluster.jobHeader=#PBS -l nodes=1:ppn=8,mem=24GB,walltime=0:30:00
# We expect RDP to need more resources than most modules
RdpClassifier.jobHeader=#PBS -l nodes=1:ppn=8,mem=24GB,walltime=4:00:00
